{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSN Pipelines: pycisTopic QC report\n",
    "\n",
    "scATAC-seq quality control and cell calling from pycisTopic (https://github.com/aertslab/pycisTopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycisTopic\n",
    "pycisTopic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybiomart as pbm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads(WORKFLOW_PARAMETERS)\n",
    "\n",
    "sample_ids = SAMPLES.split(',')\n",
    "\n",
    "print(f\"SAMPLES: {sample_ids}\")\n",
    "print(f\"pycisTopic parameters: {json.dumps(params, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "infile = open(METADATAPKL, 'rb')\n",
    "metadata_bc_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load profile data\n",
    "infile = open(PROFDATAPKL, 'rb')\n",
    "profile_data_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.qc import plot_sample_metrics\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-sample metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in profile_data_dict:\n",
    "    plot_sample_metrics({sample_id: profile_data_dict[sample_id]},\n",
    "               profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "               insert_size_distriubtion_xlim=[0,600],\n",
    "               ncol=4,\n",
    "               cmap='tab20',\n",
    "               plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined sample metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_metrics(profile_data_dict,\n",
    "           profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "           insert_size_distriubtion_xlim=[0,600],\n",
    "           ncol=4,\n",
    "           cmap='tab20',\n",
    "           plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frag_qc(x, y, \n",
    "                 ax,\n",
    "                 x_thr_min=None, x_thr_max=None,\n",
    "                 y_thr_min=None, y_thr_max=None,\n",
    "                 ylab=None,\n",
    "                 xlab=\"Number of (unique) fragments\",\n",
    "                 cmap='viridis',\n",
    "                 density_overlay=False,\n",
    "                 s=10,\n",
    "                 marker='+',\n",
    "                 c='#343434',\n",
    "                 xlim=None,\n",
    "                 ylim=None,\n",
    "                 **kwargs\n",
    "                ):\n",
    "    assert all(x.index == y.index)\n",
    "    barcodes = x.index.values\n",
    "    if density_overlay:\n",
    "        xy = np.vstack([np.log(x),y])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        idx = z.argsort()\n",
    "        x, y, z, barcodes = x[idx], y[idx], z[idx], barcodes[idx]\n",
    "    else:\n",
    "        z=c\n",
    "    barcodes_to_keep=[]\n",
    "    sp=ax.scatter(x, y, c=z, s=s, edgecolors=None, marker=marker, cmap=cmap, **kwargs)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "    # thresholds:\n",
    "    if x_thr_min is not None:    \n",
    "        ax.axvline(x=x_thr_min, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[x>x_thr_min])\n",
    "    if x_thr_max is not None:    \n",
    "        ax.axvline(x=x_thr_max, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[x<x_thr_max])\n",
    "    if y_thr_min is not None:    \n",
    "        ax.axhline(y=y_thr_min, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[y>y_thr_min])\n",
    "    if y_thr_max is not None:    \n",
    "        ax.axhline(y=y_thr_max, color='r', linestyle='--')\n",
    "        barcodes_to_keep.append(barcodes[y<y_thr_max])\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xmargin(0.01)\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlabel(xlab,fontsize=10)\n",
    "    ax.set_ylabel(ylab,fontsize=10)\n",
    "    #return barcodes_to_keep\n",
    "    if len(barcodes_to_keep)>0:\n",
    "        return list(set.intersection(*map(set, barcodes_to_keep)))\n",
    "    else:\n",
    "        return barcodes\n",
    "\n",
    "def histogram(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Draw histogram from distribution and identify centers.\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Scores distribution\n",
    "    nbins: int\n",
    "            Number of bins to use in the histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Histogram values and bin centers.\n",
    "    \"\"\"\n",
    "    array = array.ravel().flatten()\n",
    "    hist, bin_edges = np.histogram(array, bins=nbins, range=None)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "    return hist, bin_centers\n",
    "\n",
    "\n",
    "def threshold_otsu(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Apply Otsu threshold on topic-region distributions [Otsu, 1979].\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Array containing the region values for the topic to be binarized.\n",
    "    nbins: int\n",
    "            Number of bins to use in the binarization histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Binarization threshold.\n",
    "    Reference\n",
    "    ---------\n",
    "    Otsu, N., 1979. A threshold selection method from gray-level histograms. IEEE transactions on systems, man, and\n",
    "    cybernetics, 9(1), pp.62-66.\n",
    "    \"\"\" \n",
    "    hist, bin_centers = histogram(array, nbins)\n",
    "    hist = hist.astype(float)\n",
    "    # Class probabilities for all possible thresholds\n",
    "    weight1 = np.cumsum(hist)\n",
    "    weight2 = np.cumsum(hist[::-1])[::-1]\n",
    "    # Class means for all possible thresholds\n",
    "    mean1 = np.cumsum(hist * bin_centers) / weight1\n",
    "    mean2 = (np.cumsum((hist * bin_centers)[::-1]) / weight2[::-1])[::-1]\n",
    "    # Clip ends to align class 1 and class 2 variables:\n",
    "    # The last value of ``weight1``/``mean1`` should pair with zero values in\n",
    "    # ``weight2``/``mean2``, which do not exist.\n",
    "    variance12 = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n",
    "    idx = np.argmax(variance12)\n",
    "    threshold = bin_centers[:-1][idx]\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract filter thresholds from Nextflow parameters\n",
    "filter_frags_lower = {}\n",
    "filter_frags_upper = {}\n",
    "filter_tss_lower = {}\n",
    "filter_tss_upper = {}\n",
    "filter_frip_lower = {}\n",
    "filter_frip_upper = {}\n",
    "filter_dup_rate_lower = {}\n",
    "filter_dup_rate_upper = {}\n",
    "\n",
    "def float_or_none(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def extract_sample_specific_param(filter_dict, sample_id, param_key):\n",
    "    if type(params['call_cells'][param_key]) is dict:\n",
    "        if sample_id in params['call_cells'][param_key]:\n",
    "            filter_dict[sample_id] = float_or_none(params['call_cells'][param_key][sample_id])\n",
    "        else:\n",
    "            try:\n",
    "                filter_dict[sample_id] = float_or_none(params['call_cells'][param_key]['default'])\n",
    "            except KeyError:\n",
    "                print(f\"WARNING: Missing 'default' key in the sample parameters list. Filter for '{param_key}' will be missing for sample '{sample_id}'.\")\n",
    "                filter_dict[sample_id] = None\n",
    "    else:\n",
    "        filter_dict[sample_id] = float_or_none(params['call_cells'][param_key])\n",
    "    return filter_dict\n",
    "\n",
    "for s in sample_ids:\n",
    "    filter_frags_lower = extract_sample_specific_param(filter_frags_lower, s, 'filter_frags_lower')\n",
    "    filter_frags_upper = extract_sample_specific_param(filter_frags_upper, s, 'filter_frags_upper')\n",
    "    #\n",
    "    filter_tss_lower = extract_sample_specific_param(filter_tss_lower, s, 'filter_tss_lower')\n",
    "    filter_tss_upper = extract_sample_specific_param(filter_tss_upper, s, 'filter_tss_upper')\n",
    "    #\n",
    "    filter_frip_lower = extract_sample_specific_param(filter_frip_lower, s, 'filter_frip_lower')\n",
    "    filter_frip_upper = extract_sample_specific_param(filter_frip_upper, s, 'filter_frip_upper')\n",
    "    #\n",
    "    filter_dup_rate_lower = extract_sample_specific_param(filter_dup_rate_lower, s, 'filter_dup_rate_lower')\n",
    "    filter_dup_rate_upper = extract_sample_specific_param(filter_dup_rate_upper, s, 'filter_dup_rate_upper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cell filters:\n",
    "print(f\"Filter parameters:\")\n",
    "print(f\"filter_frags_lower: {json.dumps(filter_frags_lower, indent=4)}\")\n",
    "print(f\"filter_frags_upper: {json.dumps(filter_frags_upper, indent=4)}\")\n",
    "print(f\"filter_tss_lower: {json.dumps(filter_tss_lower, indent=4)}\")\n",
    "print(f\"filter_tss_upper: {json.dumps(filter_tss_upper, indent=4)}\")\n",
    "print(f\"filter_frip_lower: {json.dumps(filter_frip_lower, indent=4)}\")\n",
    "print(f\"filter_frip_upper: {json.dumps(filter_frip_upper, indent=4)}\")\n",
    "print(f\"filter_dup_rate_lower: {json.dumps(filter_dup_rate_lower, indent=4)}\")\n",
    "print(f\"filter_dup_rate_upper: {json.dumps(filter_dup_rate_upper, indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Otsu thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_kde = True\n",
    "detailed_title=params['call_cells']['use_detailed_title_on_scatterplot']\n",
    "s=4\n",
    "bc_passing_filters = {}\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(12,4), dpi=150 )\n",
    "    \n",
    "    # calculate thresholds using otsu:\n",
    "    x_arr = metadata_bc_dict[k]['Log_total_nr_frag']\n",
    "    x_threshold = threshold_otsu(x_arr, 5000)\n",
    "    x_threshold = 10**x_threshold\n",
    "\n",
    "    y_arr = metadata_bc_dict[k]['TSS_enrichment']\n",
    "    y_arr_cutoff = threshold_otsu(y_arr, 5000)\n",
    "    y_threshold = threshold_otsu(y_arr_cutoff, 5000)\n",
    "    \n",
    "    # plot everything\n",
    "    p1_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['TSS_enrichment'],\n",
    "        ylab = 'TSS Enrichment',\n",
    "        s=s,\n",
    "        x_thr_min=x_threshold,\n",
    "        y_thr_min=y_threshold,\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax1\n",
    "    )\n",
    "    p2_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['FRIP'],\n",
    "        x_thr_min=x_threshold,\n",
    "        ylab = 'FRIP',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax2\n",
    "    )\n",
    "    p3_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['Dupl_rate'],\n",
    "        x_thr_min=x_threshold,\n",
    "        ylab = 'Duplicate rate per cell',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax3\n",
    "    )\n",
    "    bc_passing_filters[k] = list(set(p1_cells) & set(p2_cells) & set(p3_cells))\n",
    "    if detailed_title:\n",
    "        med_nf = metadata_bc_dict[k].loc[bc_passing_filters[k],'Unique_nr_frag'].median()\n",
    "        med_tss = metadata_bc_dict[k].loc[bc_passing_filters[k],'TSS_enrichment'].median()\n",
    "        title = f\"{k}: Kept {len(bc_passing_filters[k])} cells. Median(fragments): {med_nf:.0f}. Median(TSS Enrichment): {med_tss:.2f} using Otsu filtering and a minimum of {x_thr_min} fragments and TSS enrichment of {y_thr_min})\"\n",
    "    else:\n",
    "        title = k\n",
    "    fig.suptitle(title, x=0.5, y=0.95, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/lustre1/project/stg_00002/lcb/fderop/data/20220419_scatac_benchmark/2_full_data_individual_samples/plts_qc/qc_otsu_{k}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bc_passing_filters_otsu.pkl', 'wb') as f:\n",
    "  pickle.dump(bc_passing_filters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T06:43:55.150843Z",
     "iopub.status.busy": "2022-05-17T06:43:55.150438Z",
     "iopub.status.idle": "2022-05-17T06:43:55.165238Z",
     "shell.execute_reply": "2022-05-17T06:43:55.164752Z"
    },
    "papermill": {
     "duration": 0.050256,
     "end_time": "2022-05-17T06:43:55.165359",
     "exception": false,
     "start_time": "2022-05-17T06:43:55.115103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write all cell barcodes selected by filtering\n",
    "if not os.path.exists('selected_barcodes'):\n",
    "    os.makedirs('selected_barcodes')\n",
    "    \n",
    "for k,v in bc_passing_filters.items():\n",
    "    pd.DataFrame(v).to_csv('selected_barcodes/'+k+'_otsu.cell_barcodes.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With predefined thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_kde = params['call_cells']['use_density_coloring_on_scatterplot']\n",
    "detailed_title=params['call_cells']['use_detailed_title_on_scatterplot']\n",
    "s=4\n",
    "bc_passing_filters = {}\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(12,4), dpi=150 )\n",
    "    p1_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['TSS_enrichment'],\n",
    "        ylab = 'TSS Enrichment',\n",
    "        s=s,\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        y_thr_min=filter_tss_lower[k],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax1\n",
    "    )\n",
    "    p2_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['FRIP'],\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        ylab = 'FRIP',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax2\n",
    "    )\n",
    "    p3_cells = plot_frag_qc(\n",
    "        x = metadata_bc_dict[k]['Unique_nr_frag'],\n",
    "        y = metadata_bc_dict[k]['Dupl_rate'],\n",
    "        x_thr_min=filter_frags_lower[k],\n",
    "        ylab = 'Duplicate rate per cell',\n",
    "        s=s,\n",
    "        ylim=[0,1],\n",
    "        density_overlay=include_kde,\n",
    "        ax=ax3\n",
    "    )\n",
    "    bc_passing_filters[k] = list(set(p1_cells) & set(p2_cells) & set(p3_cells))\n",
    "    if detailed_title:\n",
    "        med_nf = metadata_bc_dict[k].loc[bc_passing_filters[k],'Unique_nr_frag'].median()\n",
    "        med_tss = metadata_bc_dict[k].loc[bc_passing_filters[k],'TSS_enrichment'].median()\n",
    "        title = f\"{k}: Kept {len(bc_passing_filters[k])} cells. Median(fragments): {med_nf:.0f}. Median(TSS Enrichment): {med_tss:.2f})\"\n",
    "    else:\n",
    "        title = k\n",
    "    fig.suptitle(title, x=0.5, y=0.95, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bc_passing_filters.pkl', 'wb') as f:\n",
    "  pickle.dump(bc_passing_filters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all barcodes selected in compute_qc_stats (with nFrag>x)\n",
    "if not os.path.exists('selected_barcodes_nFrag'):\n",
    "    os.makedirs('selected_barcodes_nFrag')\n",
    "    \n",
    "for k,v in metadata_bc_dict.items():\n",
    "    pd.DataFrame(v.index).to_csv('selected_barcodes_nFrag/'+k+'.barcodes_nFrag_thr.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all cell barcodes selected by filtering\n",
    "if not os.path.exists('selected_barcodes'):\n",
    "    os.makedirs('selected_barcodes')\n",
    "    \n",
    "for k,v in bc_passing_filters.items():\n",
    "    pd.DataFrame(v).to_csv('selected_barcodes/'+k+'.cell_barcodes.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pycisTopic barcode metrics plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.qc import plot_barcode_metrics\n",
    "from pycisTopic.utils import fig2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_or_log10(x):\n",
    "    return None if x is None else np.log10(x)\n",
    "\n",
    "for k,v in metadata_bc_dict.items():\n",
    "\n",
    "    FRIP_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                            var_x='Log_unique_nr_frag',\n",
    "                                            var_y='FRIP',\n",
    "                                            min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                            max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                            min_y=filter_frip_lower[k],\n",
    "                                            max_y=filter_frip_upper[k],\n",
    "                                            return_cells=False,\n",
    "                                            return_fig=True,\n",
    "                                            plot=False,\n",
    "                                            )\n",
    "\n",
    "    TSS_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                           var_x='Log_unique_nr_frag',\n",
    "                                           var_y='TSS_enrichment',\n",
    "                                           min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                           max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                           min_y=filter_tss_lower[k],\n",
    "                                           max_y=filter_tss_upper[k],\n",
    "                                           return_cells=False,\n",
    "                                           return_fig=True,\n",
    "                                           plot=False\n",
    "                                           )\n",
    "\n",
    "    DR_NR_FRAG_fig = plot_barcode_metrics(metadata_bc_dict[k],\n",
    "                                          var_x='Log_unique_nr_frag',\n",
    "                                          var_y='Dupl_rate',\n",
    "                                          min_x=none_or_log10(filter_frags_lower[k]),\n",
    "                                          max_x=none_or_log10(filter_frags_upper[k]),\n",
    "                                          min_y=filter_dup_rate_lower[k],\n",
    "                                          max_y=filter_dup_rate_upper[k],\n",
    "                                          return_cells=False,\n",
    "                                          return_fig=True,\n",
    "                                          plot=False\n",
    "                                          )\n",
    "    fig=plt.figure(figsize=(30,7.5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    img = fig2img(TSS_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    img = fig2img(FRIP_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    img = fig2img(DR_NR_FRAG_fig)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    fig.suptitle(k, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pd.DataFrame([\n",
    "    list(bc_passing_filters),\n",
    "    [ len(bc_passing_filters[x]) for x in bc_passing_filters ]\n",
    "\n",
    "]).T\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4), dpi=150 )\n",
    "g=sns.barplot(x=1, y=0, data=tp,\n",
    "           palette='tab20')\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()    # get bar length\n",
    "    ax.text(width,           # set the text at 1 unit right of the bar\n",
    "            p.get_y() + p.get_height() / 2, # get Y coordinate + X coordinate / 2\n",
    "            '{:1.0f}'.format(width), # set variable to display, 2 decimals\n",
    "            ha = 'right',   # horizontal alignment\n",
    "            va = 'center')  # vertical alignment\n",
    "ax.set_xlabel(\"Number of cells\",fontsize=10)\n",
    "ax.set_ylabel(\"\",fontsize=10)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker as mticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats_violin(\n",
    "    data,\n",
    "    ax,\n",
    "    var = 'Unique_nr_frag',\n",
    "    ylab='Number of (unique) fragments',\n",
    "    xlab='',\n",
    "    logscale=True,\n",
    "    **kwargs\n",
    "    ):\n",
    "\n",
    "    tp = []\n",
    "    for k,v in data.items():\n",
    "        tmp = pd.DataFrame(np.log10(data[k][var])) if logscale else pd.DataFrame(data[k][var])\n",
    "        tmp['Sample'] = k\n",
    "        tp.append(tmp)\n",
    "    tp = pd.concat(tp, join='outer', axis=0)\n",
    "\n",
    "    yrange = [ int(math.floor(tp[var].min())), int(math.ceil(tp[var].max())) ]\n",
    "    \n",
    "    g = sns.violinplot(data=tp, x='Sample', y=var,\n",
    "                       dodge=True,\n",
    "                       linewidth=0.5,\n",
    "                       inner='quartiles',\n",
    "                       ax=ax, kind='kde',\n",
    "                       **kwargs)\n",
    "    \n",
    "    ax.set_xlabel(xlab,fontsize=10)\n",
    "    ax.set_ylabel(ylab,fontsize=10)\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=15, ha='right', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    ylab='log10 Number of (unique) fragments',\n",
    "    var='Unique_nr_frag')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='TSS enrichment',\n",
    "    var='TSS_enrichment')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #palette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='Duplicate rate',\n",
    "    var='Dupl_rate')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,4), dpi=150 )\n",
    "\n",
    "plot_stats_violin(\n",
    "    metadata_bc_dict,\n",
    "    ax=ax1,\n",
    "    split=False,\n",
    "    #alette='tab20',\n",
    "    color=\"#a6a6a6\",\n",
    "    logscale=False,\n",
    "    ylab='FRIP',\n",
    "    var='FRIP')\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
