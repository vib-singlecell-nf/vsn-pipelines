{
 "metadata": {
  "kernelspec": {
   "name": "python",
   "display_name": "Pyolite",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# VSN Pipelines: pycisTopic QC report\n\nscATAC-seq quality control and cell calling from pycisTopic (https://github.com/aertslab/pycisTopic)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pycisTopic\n",
    "\n",
    "pycisTopic.__version__"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import pybiomart as pbm\nimport pandas as pd\nimport pickle\nimport re\nimport os\nimport json\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nimport multiprocessing as mp  # for kde multithreading calculation\n\n%matplotlib inline",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "params = json.loads(WORKFLOW_PARAMETERS)\n",
    "\n",
    "sample_ids = SAMPLES.split(\",\")\n",
    "\n",
    "print(f\"SAMPLES: {sample_ids}\")\n",
    "print(f\"pycisTopic parameters: {json.dumps(params, indent=4)}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## QC summary",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from pycisTopic.qc import plot_sample_metrics\nfrom scipy.stats import gaussian_kde",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Per-sample metrics",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "for sample_id in profile_data_dict:\n    plot_sample_metrics({sample_id: profile_data_dict[sample_id]},\n               profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n               insert_size_distriubtion_xlim=[0,600],\n               ncol=4,\n               cmap='tab20',\n               plot=True)\nplt.show()",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Combined sample metrics",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "plot_sample_metrics(profile_data_dict,\n           profile_list=['barcode_rank_plot', 'insert_size_distribution', 'profile_tss', 'frip'],\n           insert_size_distriubtion_xlim=[0,600],\n           ncol=4,\n           cmap='tab20',\n           plot=True)\nplt.show()",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Cell calling",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create definition for multiprocessing kde calculation.\n",
    "def calc_kde(xy):\n",
    "    return gaussian_kde(xy)(xy)\n",
    "\n",
    "\n",
    "def plot_frag_qc(\n",
    "    x,\n",
    "    y,\n",
    "    ax,\n",
    "    x_thr_min=None,\n",
    "    x_thr_max=None,\n",
    "    y_thr_min=None,\n",
    "    y_thr_max=None,\n",
    "    ylab=None,\n",
    "    xlab=\"Number of (unique) fragments\",\n",
    "    cmap=\"viridis\",\n",
    "    density_overlay=False,\n",
    "    s=10,\n",
    "    marker=\"+\",\n",
    "    c=\"#343434\",\n",
    "    xlim=None,\n",
    "    ylim=None,\n",
    "    **kwargs\n",
    "):\n",
    "    assert all(x.index == y.index)\n",
    "    barcodes = x.index.values\n",
    "\n",
    "    if density_overlay:\n",
    "        cores = 8\n",
    "\n",
    "        x_log = np.log(x)\n",
    "\n",
    "        # Split input array for KDE [log(x), y] array in\n",
    "        # equaly spaced parts (start_offset + n * nbr_cores).\n",
    "        kde_parts = [np.vstack([x_log[i::cores], y[i::cores]]) for i in range(cores)]\n",
    "\n",
    "        # Get nultiprocess context object to spawn processes.\n",
    "        mp_ctx = mp.get_context(\"spawn\")\n",
    "\n",
    "        # Calculate KDE in parallel.\n",
    "        with mp_ctx.Pool(processes=cores) as pool:\n",
    "            results = pool.map(calc_kde, kde_parts)\n",
    "\n",
    "        z = np.concatenate(results)\n",
    "\n",
    "        idx = z.argsort()\n",
    "        x, y, z, barcodes = x[idx], y[idx], z[idx], barcodes[idx]\n",
    "    else:\n",
    "        z = c\n",
    "\n",
    "    sp = ax.scatter(x, y, c=z, s=s, edgecolors=None, marker=marker, cmap=cmap, **kwargs)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "\n",
    "    # Start with keeping all barcodes.\n",
    "    barcodes_to_keep = np.full(x.shape[0], True)\n",
    "\n",
    "    # Filter barcodes out if needed based on thresholds:\n",
    "    if x_thr_min is not None:\n",
    "        ax.axvline(x=x_thr_min, color=\"r\", linestyle=\"--\")\n",
    "        barcodes_to_keep &= x > x_thr_min\n",
    "    if x_thr_max is not None:\n",
    "        ax.axvline(x=x_thr_max, color=\"r\", linestyle=\"--\")\n",
    "        barcodes_to_keep &= x < x_thr_max\n",
    "    if y_thr_min is not None:\n",
    "        ax.axhline(y=y_thr_min, color=\"r\", linestyle=\"--\")\n",
    "        barcodes_to_keep &= y > y_thr_min\n",
    "    if y_thr_max is not None:\n",
    "        ax.axhline(y=y_thr_max, color=\"r\", linestyle=\"--\")\n",
    "        barcodes_to_keep &= y < y_thr_max\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xmargin(0.01)\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlabel(xlab, fontsize=10)\n",
    "    ax.set_ylabel(ylab, fontsize=10)\n",
    "\n",
    "    return barcodes[barcodes_to_keep]\n",
    "\n",
    "\n",
    "def histogram(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Draw histogram from distribution and identify centers.\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Scores distribution\n",
    "    nbins: int\n",
    "            Number of bins to use in the histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Histogram values and bin centers.\n",
    "    \"\"\"\n",
    "    array = array.ravel().flatten()\n",
    "    hist, bin_edges = np.histogram(array, bins=nbins, range=None)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
    "    return hist, bin_centers\n",
    "\n",
    "\n",
    "def threshold_otsu(array, nbins=100):\n",
    "    \"\"\"\n",
    "    Apply Otsu threshold on topic-region distributions [Otsu, 1979].\n",
    "    Parameters\n",
    "    ---------\n",
    "    array: `class::np.array`\n",
    "            Array containing the region values for the topic to be binarized.\n",
    "    nbins: int\n",
    "            Number of bins to use in the binarization histogram\n",
    "    Return\n",
    "    ---------\n",
    "    float\n",
    "            Binarization threshold.\n",
    "    Reference\n",
    "    ---------\n",
    "    Otsu, N., 1979. A threshold selection method from gray-level histograms. IEEE transactions on systems, man, and\n",
    "    cybernetics, 9(1), pp.62-66.\n",
    "    \"\"\"\n",
    "    hist, bin_centers = histogram(array, nbins)\n",
    "    hist = hist.astype(float)\n",
    "    # Class probabilities for all possible thresholds\n",
    "    weight1 = np.cumsum(hist)\n",
    "    weight2 = np.cumsum(hist[::-1])[::-1]\n",
    "    # Class means for all possible thresholds\n",
    "    mean1 = np.cumsum(hist * bin_centers) / weight1\n",
    "    mean2 = (np.cumsum((hist * bin_centers)[::-1]) / weight2[::-1])[::-1]\n",
    "    # Clip ends to align class 1 and class 2 variables:\n",
    "    # The last value of ``weight1``/``mean1`` should pair with zero values in\n",
    "    # ``weight2``/``mean2``, which do not exist.\n",
    "    variance12 = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n",
    "    idx = np.argmax(variance12)\n",
    "    threshold = bin_centers[:-1][idx]\n",
    "    return threshold"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# extract filter thresholds from Nextflow parameters\n",
    "filter_frags_lower = {}\n",
    "filter_frags_upper = {}\n",
    "filter_tss_lower = {}\n",
    "filter_tss_upper = {}\n",
    "filter_frip_lower = {}\n",
    "filter_frip_upper = {}\n",
    "filter_dup_rate_lower = {}\n",
    "filter_dup_rate_upper = {}\n",
    "\n",
    "\n",
    "def float_or_none(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_sample_specific_param(filter_dict, sample_id, param_key):\n",
    "    if type(params[\"call_cells\"][param_key]) is dict:\n",
    "        if sample_id in params[\"call_cells\"][param_key]:\n",
    "            filter_dict[sample_id] = float_or_none(\n",
    "                params[\"call_cells\"][param_key][sample_id]\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                filter_dict[sample_id] = float_or_none(\n",
    "                    params[\"call_cells\"][param_key][\"default\"]\n",
    "                )\n",
    "            except KeyError:\n",
    "                print(\n",
    "                    f\"WARNING: Missing 'default' key in the sample parameters list. Filter for '{param_key}' will be missing for sample '{sample_id}'.\"\n",
    "                )\n",
    "                filter_dict[sample_id] = None\n",
    "    else:\n",
    "        filter_dict[sample_id] = float_or_none(params[\"call_cells\"][param_key])\n",
    "    return filter_dict\n",
    "\n",
    "\n",
    "for s in sample_ids:\n",
    "    filter_frags_lower = extract_sample_specific_param(\n",
    "        filter_frags_lower, s, \"filter_frags_lower\"\n",
    "    )\n",
    "    filter_frags_upper = extract_sample_specific_param(\n",
    "        filter_frags_upper, s, \"filter_frags_upper\"\n",
    "    )\n",
    "    #\n",
    "    filter_tss_lower = extract_sample_specific_param(\n",
    "        filter_tss_lower, s, \"filter_tss_lower\"\n",
    "    )\n",
    "    filter_tss_upper = extract_sample_specific_param(\n",
    "        filter_tss_upper, s, \"filter_tss_upper\"\n",
    "    )\n",
    "    #\n",
    "    filter_frip_lower = extract_sample_specific_param(\n",
    "        filter_frip_lower, s, \"filter_frip_lower\"\n",
    "    )\n",
    "    filter_frip_upper = extract_sample_specific_param(\n",
    "        filter_frip_upper, s, \"filter_frip_upper\"\n",
    "    )\n",
    "    #\n",
    "    filter_dup_rate_lower = extract_sample_specific_param(\n",
    "        filter_dup_rate_lower, s, \"filter_dup_rate_lower\"\n",
    "    )\n",
    "    filter_dup_rate_upper = extract_sample_specific_param(\n",
    "        filter_dup_rate_upper, s, \"filter_dup_rate_upper\"\n",
    "    )"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# show cell filters:\nprint(f\"Filter parameters:\")\nprint(f\"filter_frags_lower: {json.dumps(filter_frags_lower, indent=4)}\")\nprint(f\"filter_frags_upper: {json.dumps(filter_frags_upper, indent=4)}\")\nprint(f\"filter_tss_lower: {json.dumps(filter_tss_lower, indent=4)}\")\nprint(f\"filter_tss_upper: {json.dumps(filter_tss_upper, indent=4)}\")\nprint(f\"filter_frip_lower: {json.dumps(filter_frip_lower, indent=4)}\")\nprint(f\"filter_frip_upper: {json.dumps(filter_frip_upper, indent=4)}\")\nprint(f\"filter_dup_rate_lower: {json.dumps(filter_dup_rate_lower, indent=4)}\")\nprint(f\"filter_dup_rate_upper: {json.dumps(filter_dup_rate_upper, indent=4)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Using Otsu thresholding",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def plot_qc(\n    sample,\n    metadata_bc_df,\n    include_kde=True,\n    detailed_title=params[\"call_cells\"][\"use_detailed_title_on_scatterplot\"],\n    s=4,\n):\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), dpi=150)\n\n    # calculate thresholds using otsu:\n    x_arr = metadata_bc_df[\"Log_total_nr_frag\"]\n    x_threshold = threshold_otsu(x_arr, 5000)\n    x_threshold = 10**x_threshold\n\n    y_arr = metadata_bc_df[\"TSS_enrichment\"]\n    y_arr_cutoff = threshold_otsu(y_arr, 5000)\n    y_threshold = threshold_otsu(y_arr_cutoff, 5000)\n\n    # plot everything\n    p1_cells = plot_frag_qc(\n        x=metadata_bc_df[\"Unique_nr_frag\"],\n        y=metadata_bc_df[\"TSS_enrichment\"],\n        ylab=\"TSS Enrichment\",\n        s=s,\n        x_thr_min=x_threshold,\n        y_thr_min=y_threshold,\n        density_overlay=include_kde,\n        ax=ax1,\n    )\n    p2_cells = plot_frag_qc(\n        x=metadata_bc_df[\"Unique_nr_frag\"],\n        y=metadata_bc_df[\"FRIP\"],\n        x_thr_min=x_threshold,\n        ylab=\"FRIP\",\n        s=s,\n        ylim=[0, 1],\n        density_overlay=include_kde,\n        ax=ax2,\n    )\n    p3_cells = plot_frag_qc(\n        x=metadata_bc_df[\"Unique_nr_frag\"],\n        y=metadata_bc_df[\"Dupl_rate\"],\n        x_thr_min=x_threshold,\n        ylab=\"Duplicate rate per cell\",\n        s=s,\n        ylim=[0, 1],\n        density_overlay=include_kde,\n        ax=ax3,\n    )\n    bc_passing_filters = list(set(p1_cells) & set(p2_cells) & set(p3_cells))\n    if detailed_title:\n        med_nf = metadata_bc_df.loc[bc_passing_filters, \"Unique_nr_frag\"].median()\n        med_tss = metadata_bc_df.loc[bc_passing_filters, \"TSS_enrichment\"].median()\n        med_frip = metadata_bc_df.loc[bc_passing_filters, \"FRIP\"].median()\n        title = f\"{sample}: Kept {len(bc_passing_filters)} cells using Otsu filtering. Median(fragments): {med_nf:.0f}. Median(TSS Enrichment): {med_tss:.2f}). Median FRIP: {med_frip:.2f}\\nUsed a minimum of {x_threshold} fragments and TSS enrichment of {y_threshold})\"\n    else:\n        title = sample\n\n    fig.suptitle(title, x=0.5, y=0.95, fontsize=10)\n    plt.tight_layout()\n    plt.savefig(f\"plots_qc/qc_otsu_{sample}.png\", dpi=300, facecolor=\"white\")\n    plt.show()\n    return bc_passing_filters, fig",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"selected_barcodes\"):\n",
    "    os.makedirs(\"selected_barcodes\")\n",
    "if not os.path.exists(\"plots_qc\"):\n",
    "    os.makedirs(\"plots_qc\")\n",
    "\n",
    "for sample in sample_ids:\n",
    "    with open(f\"metadata/{sample}.metadata.pkl\", \"rb\") as fh:\n",
    "        metadata_bc_df = pickle.load(fh)\n",
    "\n",
    "    bc_passing_filters, fig = plot_qc(sample, metadata_bc_df)\n",
    "    with open(f\"selected_barcodes/{sample}_bc_passing_filters_otsu.pkl\", \"wb\") as fh:\n",
    "        pickle.dump(bc_passing_filters, fh)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
